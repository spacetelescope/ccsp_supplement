{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04942737-7b27-41de-ab74-929e784fd2fe",
   "metadata": {},
   "source": [
    "# An Example ASDF Design Workflow for CCSPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11569a7-f499-491f-abd3-d0a5782c0447",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this notebook, we'll illustrate one possible method for starting to incorporate ASDF file design into your workflow and pipeline.\n",
    "\n",
    "We'll assume here that you're starting with a FITS file, though there is no need to do so. We'll extract the WCS from this FITS file's header and convert it into something ASDF-flavored, and then we'll extract the rest of the metadata from the FITS header. (But if you need more a complicated WCS than FITS can easily support, or if you are making alterations to a Roman ASDF file, then you probably *shouldn't* start with a FITS File.)\n",
    "\n",
    "The rest of the example design process would, in full, go something like this:\n",
    "- Design an ASDF tree structure and sample content for your product, passing nested dictionaries into an ASDF file object.\n",
    "- Save the resultant ASDF file object to an ASDF file: your initial sample file (without a corresponding schema).\n",
    "- Draft a schema that matches the initial sample file you just designed, in consultation with MAST and the RAD maintainers. Send the initial sample file and draft schema to MAST and the RAD maintainers in a Github issue to the RAD repository, which will evolve into a pull request in consultation with MAST and the RAD maintainers. **Note:** We'll largely elide the details of this step in this notebook. For more information on the schema-writing part of the process, see the [File Design Guidelines](https://outerspace.stsci.edu/spaces/DraftMASTCONTRIB/pages/344588706/.File+Design+for+PITs+v1.0#id-.FileDesignforPITsv1.0-Requirements).\n",
    "- Install the appropriate branch/fork of the RAD and roman_datamodels (with MAST and the RAD's help) into your pipeline environment.\n",
    "- Pass your ASDF tree into a Roman data model object. Save the result as your revised sample file, which now tags your schema, and deliver it to MAST for validation.\n",
    "\n",
    "**Note:** this is not the only possible workflow. For example, some people prefer to design the schema first, before constructing the ASDF file object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25895c-629c-421d-a123-7168740862a5",
   "metadata": {},
   "source": [
    "## Imports and installations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac22ca-0538-4edb-aab3-72a64a87f04c",
   "metadata": {},
   "source": [
    "Later, we'll need a particular branch in a particular fork of the `roman_datamodels` repository, where we've set up an ASDF schema and Roman data model for the product we'll be converting. You should only use this fork in the context of this specific notebook; when you're ready to start working on your own data, install the main branch of [roman_datamodels](https://github.com/spacetelescope/roman_datamodels) proper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3642a987-2178-448d-8750-ed2637414c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured\n",
    "!pip install git+https://github.com/adrianlucy/roman_datamodels.git@ccsp_schemas_for_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771e420-8dc4-4f93-8f60-bb5c9cea99d4",
   "metadata": {},
   "source": [
    "You may need to restart your kernel for that to take effect.\n",
    "\n",
    "That installation, incidentally, installed everything else that we need as dependencies. So now let's run our imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da07c96-10f3-4e2b-be24-3be2bcefce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits  # For loading the FITS file that we'll convert\n",
    "import numpy as np  # For array and matrix wrangling\n",
    "\n",
    "import asdf  # For building the ASDF tree\n",
    "\n",
    "from astropy.time import Time  # For passing Time objects into the ASDF tree\n",
    "\n",
    "import gwcs  # For building the WCS\n",
    "from gwcs import coordinate_frames as cf  # For building the WCS\n",
    "from astropy.modeling import models  # For building the WCS\n",
    "from astropy import coordinates as coord  # For building the WCS\n",
    "\n",
    "import roman_datamodels.datamodels as rdm  # Only used for the final step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975c29a7-89eb-4853-8e0c-d52cffd0892f",
   "metadata": {},
   "source": [
    "## Opening the FITS file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb9db35-d507-4cd2-8c9e-dcf7094d03cd",
   "metadata": {},
   "source": [
    "Next, we'll open the FITS file that we want to convert to ASDF. For the purposes of this tutorial, we'll use a simple 2D image file from the [FIMS-SPEAR mission](https://outerspace.stsci.edu/spaces/SPEARFIMS/overview). The main science data array is in the primary HDU, which is accompanied by concomitant images of net photon counts and an exposure map in HDU1 and HDU2, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85642bf-71ef-495a-af87-6812ebcd4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For best practice, in your pipeline this would be `with fits.open(\"filename\"):`\n",
    "# Get what you need, then close the file.\n",
    "hdul = fits.open(\"https://archive.stsci.edu/mccm/fims-spear/spear/vela/mccm_fims-spear_spear-ap100_vela_long-c-iv_v1.0_img.fits\")\n",
    "\n",
    "hdul.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7461fa57-a454-49ec-8683-0fd6e6100805",
   "metadata": {},
   "source": [
    "Let's take a look at the headers for each HDU. We see that most of the metadata is in the primary header, and that the concomitant images share the primary array's World Coordinate System (WCS). The WCS maps the array pixel coordinates to world coordinates like wavelength, time, or (in this case) sky coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48740c00-41bc-44df-b186-be86e664cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "header0 = hdul[0].header\n",
    "header0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b53735-8db7-41b3-a84e-a7244044ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul[1].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601eb75-8d7c-49e3-925d-9ae91b3c7c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul[2].header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f3b58-426a-43aa-a3a1-fa99c4c95cea",
   "metadata": {},
   "source": [
    "## Converting FITS WCS to GWCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88e8d2-a0c3-4be7-8513-0b3fe2b371c5",
   "metadata": {},
   "source": [
    "Next, we'll use `gwcs.utils.make_fitswcs_transform` to convert the FITS WCS keywords into a `GWCS` transform. `GWCS` is ASDF's solution for storing complex WCS solutions with distortions and/or nonlinear components. In this case, the WCS is a simple gnomonic (\"TAN\") projection, but we can get a feel for how ASDF thinks about WCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ebce11-015d-45bd-995c-4274385be67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the transform from the FITS header\n",
    "transform = gwcs.utils.make_fitswcs_transform(header0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc815d0-dcf9-4f86-8146-c3709c5977e4",
   "metadata": {},
   "source": [
    "`make_fitswcs_transform` doesn't identify the input and output frame, so we'll need to specify those manually. Looking at the FITS header, we see that the output world coordinates are in ICRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f9beb-2c4f-45a3-b705-75694c45ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the frames\n",
    "pixel_frame = cf.Frame2D(axes_names=('x','y'), name='pixel')  # Input pixel frame\n",
    "sky_frame = cf.CelestialFrame(reference_frame=coord.ICRS(),\n",
    "                              axes_names=('ra','dec'),\n",
    "                              name='icrs',\n",
    "                              axis_physical_types = ('pos.eq.ra', 'pos.eq.dec'))  # Use the UCDs for RA/Dec in the axis_physical_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b38018-3e9a-4348-be67-81a60c86fea9",
   "metadata": {},
   "source": [
    "Finally, we'll pass the transform and the input/output frames into a `GWCS` WCS object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8031e853-c72f-4481-bfbf-6bc5757d2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcs = gwcs.WCS(forward_transform=transform, input_frame=pixel_frame, output_frame=sky_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65f837-c8a7-40fe-ab42-3e2e0621336f",
   "metadata": {},
   "source": [
    "Let's take a look at that WCS object. We see that it is comprised of a single (multi-component) transform step from pixel to ICRS coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4135026-8252-4bba-904d-cdf906b935dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab19ca-5191-4eb7-95fb-8ba926807d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064fb590-c3bb-4bb1-8b16-eaafb1b21d48",
   "metadata": {},
   "source": [
    "Note FITS pixel indexing is 1-based while ASDF/Python indexing is 0-based, so the `CRVALi` sky coordinates are offset by 1 pixel from the `CRPIXj` pixel coordinates in the FITS header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb8027-82e2-432f-a5b2-deba11af0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(header0['CRVAL1'], header0['CRVAL2'])\n",
    "\n",
    "print(wcs.pixel_to_world(header0['CRPIX1']-1, header0['CRPIX2']-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71442e-843a-4419-89ad-74de2fb86ca6",
   "metadata": {},
   "source": [
    "Just to double-check the work of `make_fitswcs_transform`, we can also try following the \"[FITS Equivalent WCS Example](https://gwcs.readthedocs.io/en/latest/gwcs/fits_analog.html)\" workflow from the GWCS documentation. We'll make two small changes to that example: drop the use of astropy units, and (for precision in nomenclature when `CDELTi != 1`) drop `rotation.input_units_equivalencies` in favor of a `models.Scale` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a9b7e-61c1-49e1-ad74-0489ebc69cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted directly from https://gwcs.readthedocs.io/en/latest/gwcs/fits_analog.html\n",
    "\n",
    "# Adjust by 1 to accomodate the different indexing\n",
    "shift_by_crpix = models.Shift(-(header0['CRPIX1'] - 1)) & models.Shift(-(header0['CRPIX2'] - 1))\n",
    "\n",
    "# Set the PCi_j matrix\n",
    "try:\n",
    "    matrix = np.array([[header0['PC1_1'], header0['PC1_2']],\n",
    "                       [header0['PC2_1'], header0['PC2_2']]])\n",
    "except KeyError:  # If PC1_2, PC2_1 are not present\n",
    "    matrix = np.array([[header0['PC1_1'], 0.0],\n",
    "                       [0.0, header0['PC2_2']]])\n",
    "\n",
    "# Apply the pixel scale\n",
    "scale = (models.Scale(header0['CDELT1']) & models.Scale(header0['CDELT2']))\n",
    "\n",
    "# Apply the PCi_j matrix to rotate the inputs\n",
    "rotation = models.AffineTransformation2D(matrix, translation=[0, 0])\n",
    "rotation.inverse = models.AffineTransformation2D(np.linalg.inv(matrix), translation=[0, 0])\n",
    "\n",
    "# Apply a gnomonic projection\n",
    "tan = models.Pix2Sky_TAN()\n",
    "\n",
    "# Apply a rotation on the sky using CRVAL.\n",
    "celestial_rotation =  models.RotateNative2Celestial(header0['CRVAL1'], header0['CRVAL2'], 180)\n",
    "\n",
    "# Combine all the steps into a single transform\n",
    "det2sky = shift_by_crpix | rotation | scale | tan | celestial_rotation\n",
    "det2sky.name = \"linear_transform\"\n",
    "\n",
    "# Define the frames as before\n",
    "pixel_frame = cf.Frame2D(axes_names=('x','y'), name='pixel')  # Input pixel frame\n",
    "sky_frame = cf.CelestialFrame(reference_frame=coord.ICRS(),\n",
    "                              axes_names=('ra','dec'),\n",
    "                              name='icrs',\n",
    "                              axis_physical_types = ('pos.eq.ra', 'pos.eq.dec'))  # Use the UCDs for RA/Dec in the axis_physical_types\n",
    "\n",
    "# Put the transform and the frames together\n",
    "pipeline = [(pixel_frame, det2sky), (sky_frame, None)]\n",
    "\n",
    "# Pass them into a gwcs WCS object\n",
    "wcs_manual = gwcs.WCS(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b5f15-1d61-4311-8aae-ad3a83c20f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wcs_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e756e-dc15-4df9-a3ae-e5dd1c451b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcs_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4050fe8-a570-47a0-841f-c781e2979a1c",
   "metadata": {},
   "source": [
    "That looks like the same WCS object! Let's double-check over an arbitrary range of pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399858b-333e-4e58-9bf4-f79e6f2b2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range (-20,-20):\n",
    "    for y in range(-20,20):\n",
    "        test = np.asarray(wcs(x,y)) - np.asarray(wcs_manual(x,y))\n",
    "        if test.any() != 0:\n",
    "            print(\"The WCS's don't match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed2786-56a4-43a0-a55f-0e8502a7c5f5",
   "metadata": {},
   "source": [
    "If you're having trouble constructing a WCS for your data, your MAST and SOC contacts are happy to help, and can consult with the `gwcs` developers on your behalf as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29a1d7f-275a-4d82-bef0-6804c72d56e2",
   "metadata": {},
   "source": [
    "## Assembling metadata dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c35f1-34e3-453e-8bea-f927b451ea78",
   "metadata": {},
   "source": [
    "Next, we'll pass a variety of metadata (including the WCS object we created above) from the FITS header into Python dictionaries, before we construct our ASDF file object.\n",
    "\n",
    "Let's take a look at the [archival common metadata table in the expandable linked here](https://outerspace.stsci.edu/spaces/DraftMASTCONTRIB/pages/344588706/.File+Design+for+PITs+v1.0#id-.FileDesignforPITsv1.0-pits_common) (or if you prefer to look at schemas, see [ccsp_minimal](https://rad--747.org.readthedocs.build/en/747/generated/schemas/CCSP/ccsp_minimal-1.0.0.html) and [ccsp_custom_product](https://rad--747.org.readthedocs.build/en/747/generated/schemas/CCSP/ccsp_custom_product-1.0.0.html)) and start filling out what we can for those keys, supplemented by the other, unique metadata found in this FITS header."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac02b4-8577-40d7-91be-f0fd96c57589",
   "metadata": {},
   "source": [
    "ASDF data and metadata can be nested in a hierarchical tree structure, collecting related information together. So we'll start with small dictionaries, and then pass those dictionaries into a top-level dictionary in a nested structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c21bf-7a04-4ada-bf28-da2da5eb42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccsp = {\n",
    "    \"name\": \"SPEAR\",\n",
    "    \"investigator\": \"Jerry Edelstein\",\n",
    "    \"archive_lead\": \"Martin Sirk\",\n",
    "    \"doi\": header0['DOI'],\n",
    "    \"file_version\": header0['VER'],\n",
    "    \"data_release_id\": \"DR1\",\n",
    "    \"license\": header0['LICENSE'],\n",
    "    \"license_url\": header0['LICENURL'],\n",
    "    \"target_name\": header0['TARG'],\n",
    "    \"intent\": \"SCIENCE\",\n",
    "    \"target_keywords\": \"Supernova remnants\",  # Chosen from https://astrothesaurus.org/concept-select/\n",
    "    \"target_keywords_id\": 1667,  # From the https://astrothesaurus.org/concept-select/ entry above\n",
    "}\n",
    "\n",
    "instrument = {\n",
    "    \"name\": header0['INSTRUME'],\n",
    "    \"detector\": None,\n",
    "    \"optical_element\": header0['FILTER'],\n",
    "}\n",
    "\n",
    "target_coordinates = {\n",
    "    \"reference_frame\": header0['RADESYS'],\n",
    "    \"ra\": header0['RA_TARG'],\n",
    "    \"dec\": header0['DEC_TARG'],\n",
    "}\n",
    "\n",
    "wavelength = {\n",
    "    \"band\": \"UV\",\n",
    "    \"minimum\": float(header0['LAM-MIN']),\n",
    "    \"maximum\": float(header0['LAM-MAX']),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb7b48-a5a1-446b-8fac-6616e20d4819",
   "metadata": {},
   "source": [
    "To populate the start and end date-times of this product, we'll convert the values from the FITS header into astropy Time objects before passing them into the dictionary, for compatibility with the ASDF Time schema.\n",
    "\n",
    "And the exposure time in the FITS header that best matches the mandatory `exposure_time` sub-key's definition is `EXP-SLIT`, so we'll use that as the characteristic exposure time under `exposure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db0f9c-ef5e-427b-b95d-64ae14e9e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = Time(header0['DATE-BEG'], format='isot', scale=header0['TIMESYS'].lower())\n",
    "end = Time(header0['DATE-END'], format='isot', scale=header0['TIMESYS'].lower())\n",
    "\n",
    "exposure = {\n",
    "    \"start_time\": start,\n",
    "    \"end_time\": end,\n",
    "    \"exposure_time\": header0['EXP-SLIT'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76aae32-8339-4cf0-b651-7c40ce732649",
   "metadata": {},
   "source": [
    "We have a lot of detail on the statistics of the exposure map, beyond the scope of the `exposure` parent key defined in [ccsp_custom_product](https://rad--747.org.readthedocs.build/en/747/generated/schemas/CCSP/ccsp_custom_product-1.0.0.html), so we'll create an `exposure_stats` tree to group this information.\n",
    "\n",
    "Because there is no character count limit on ASDF keywords, we can be slightly more verbose than we would be in FITS (e.g., `pixel_exposure_time` instead of `EXP-PIX`). Still, the definition of these keys is left to the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e593b4f-98a4-470a-8cda-5026f4fff7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_stats = {\n",
    "    \"median_exposure_time\": header0['EXP-SLIT'],\n",
    "    \"max_exposure_time\": header0['EXP-SMAX'],\n",
    "    \"min_exposure_time\": header0['EXP-SMIN'],\n",
    "    \"pixel_exposure_time\": header0['EXP-PIX'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf52be-6c33-4444-bd6b-b46fa12ff0c2",
   "metadata": {},
   "source": [
    "We'll also use our WCS object to get the sky coordinate boundaries of the image, to pass into an `s_region` keyword that will make this product discoverable in coordinate cone searches upon ingestion into MAST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28b610-e9df-4d87-910b-b54549cb461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes a fully-illuminated 2D image\n",
    "def s_region_fullchip(wcs, data):\n",
    "    s_region_parts = ['POLYGON', 'ICRS']\n",
    "    naxis1, naxis2 = data.shape  # Get pixel image shape\n",
    "\n",
    "    s_region_parts.extend([\n",
    "        str(wcs(0,0)[0]),  # RA of 1st vertex\n",
    "        str(wcs(0,0)[1]),  # Dec of 1st vertex\n",
    "        str(wcs(naxis1-1, 0)[0]),  # RA of 2nd vertex\n",
    "        str(wcs(naxis1-1, 0)[1]),  # Dec of 2nd vertex\n",
    "        str(wcs(naxis1-1, naxis2-1)[0]),  # RA of 3rd vertex\n",
    "        str(wcs(naxis1-1, naxis2-1)[1]),  # Dec of 3rd vertex\n",
    "        str(wcs(0, naxis2-1)[0]),  # RA of 4th vertex\n",
    "        str(wcs(0, naxis2-1)[1])  # Dec of 4th vertex\n",
    "    ])\n",
    "\n",
    "    s_region = \" \".join(s_region_parts)\n",
    "\n",
    "    return s_region\n",
    "\n",
    "s_region = s_region_fullchip(wcs, hdul[0].data)\n",
    "\n",
    "print(s_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeda61e-6738-470b-bd1e-86bf12536143",
   "metadata": {},
   "source": [
    "## Assembling the ASDF tree\n",
    "\n",
    "Now that we've deconstructed the FITS file and mapped much of its contents to Python dictionaries, we can construct the ASDF tree in a readable way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dde8cd-646d-4807-98f0-9677cc5d944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the ASDF tree\n",
    "af = asdf.AsdfFile({\n",
    "    \"meta\": {\n",
    "        \"wcs\": wcs,\n",
    "        \"ccsp\": ccsp,\n",
    "        \"exposure\": exposure,\n",
    "        \"exposure_stats\": exposure_stats,\n",
    "        \"instrument\": instrument,\n",
    "        \"telescope\": header0['TELESCOP'],\n",
    "        \"target_coordinates\": target_coordinates,\n",
    "        \"s_region\": s_region,\n",
    "        \"pixel_scale\": header0['CDELT1']/3600.,  # Convert deg to arcsec\n",
    "        \"wavelength\": wavelength,\n",
    "        \"aperture\": header0['APERTURE'],\n",
    "        \"grasp\": header0['GRASP']\n",
    "        \n",
    "    },\n",
    "    \"data\": hdul[0].data,\n",
    "    \"count\": hdul[1].data,\n",
    "    \"exp\": hdul[2].data,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a60bb6c-0010-45c4-881b-e8e0cb75ef14",
   "metadata": {},
   "source": [
    "Now we can write that ASDF file object to an ASDF file on-disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56113652-1674-4a0e-ba72-e6412a790353",
   "metadata": {},
   "outputs": [],
   "source": [
    "af.write_to(\"sample_file.asdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4834db28-27eb-4775-9217-6c29fa353ab6",
   "metadata": {},
   "source": [
    "At this point, you would start writing a data product schema compatible with this sample, following [the guidelines](https://outerspace.stsci.edu/spaces/DraftMASTCONTRIB/pages/344588706/.File+Design+for+PITs+v1.0#id-.FileDesignforPITsv1.0-asdfASDFFileDesign). Then, you would share this file and its corresponding schema with MAST and the RAD maintainers in a [Github issue](github.com/spacetelescope/rad/issues/new) to the RAD repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f64710-56fb-42e7-bc28-478bf5c7bca9",
   "metadata": {},
   "source": [
    "Taking a look at this sample file, we see that it's pretty good, but many of the keys aren't clearly defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9728938a-066f-4d75-bafd-93776dbec765",
   "metadata": {},
   "outputs": [],
   "source": [
    "testaf_sample = asdf.open('sample_file.asdf')\n",
    "testaf_sample.info(max_rows=None, max_cols=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb880c87-5cce-4555-b0be-108ad5041131",
   "metadata": {},
   "source": [
    "That's because key definitions and units in ASDF are externalized to the schemas, and we haven't yet linked this file to a schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050d775-c95f-4bed-bd3e-ee6037337a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(af.schema_info(\"description\",\"roman.data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058480f8-9c9a-4115-98b2-a8b655b6ab16",
   "metadata": {},
   "source": [
    "## Converting to a DataModel and tagging the schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8e2ec-3833-4f91-95a6-1f8b77b8f745",
   "metadata": {},
   "source": [
    "Now that we have the file contents mapped to ASDF, you would work on making a DataModel for the data. This would involve:\n",
    "- defining a schema\n",
    "- registering this schema using roman_datamodels\n",
    "\n",
    "Since the above changes are implemented by modifying `rad` and `roman_datamodels`, and these examples haven't been merged into a release, the following code will only work by installing the fork at `git+https://github.com/adrianlucy/roman_datamodels.git@ccsp_schemas_for_notebook`, which we did at the top of this notebook.\n",
    "\n",
    "First let's look at the added schema by providing its URI and asking asdf to load the resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd34e7-9ed4-4bf3-a916-c859bbaa9944",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource = asdf.get_config().resource_manager[\"asdf://stsci.edu/datamodels/roman/schemas/CCSP/EXAMPLE/example_spear_pointed_image-1.0.0\"]\n",
    "print(resource.decode(\"ascii\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090ecf1a-406f-4585-a13e-bc49eced4408",
   "metadata": {},
   "source": [
    "In the above schema note that:\n",
    "- the common `ccsp_custom_product-1.0.0` schema is **referenced**\n",
    "- the ASDF structure is described (and constrained) by the schema (for example, `data` must be a 2-dimensional image with float32 values and units of photons/cm^2/s/sr.\n",
    "\n",
    "The addition of this schema to RAD and a small modification to roman_datamodels allows us to use this schema for a new DataModel `ExampleSpearPointedImageModel`. Let's create a new instance of that model with the tree we constructed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46aae34-3724-4440-8209-99a721fb7e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rdm.ExampleSpearPointedImageModel.create_from_model(af.tree)\n",
    "\n",
    "model.info(max_rows=None, max_cols=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3459b94d-f586-4dd6-a894-f7f11c585c98",
   "metadata": {},
   "source": [
    "Let's try validating the model we've created against its schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5717ad-05bc-4734-8ba3-235a8273ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   model.validate()\n",
    "except asdf.exceptions.ValidationError as err:\n",
    "    print(f\"ValidationError({err.message})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab14d9b0-a24b-4f05-8150-d94befb385c8",
   "metadata": {},
   "source": [
    "Oops! We've forgotten to add the required `file_date` key. Let's do that, and try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da8c19-4a55-4f47-b88f-454c37fd8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[\"meta\"][\"file_date\"] = Time(Time.now(), format='isot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc34fc-e890-49f9-ad16-e6889cd4c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   model.validate()\n",
    "except asdf.exceptions.ValidationError as err:\n",
    "    print(f\"ValidationError({err.message})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d44ca0-510e-41c3-bfbb-a9d88259c524",
   "metadata": {},
   "source": [
    "Now that our model is valid we can save it to an ASDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd60f8-ffc4-47d7-9ae7-ac13cb4dd2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ccsp_example_spear_vela_long-c-iv_v0.0_img.asdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14987435-1cea-49e2-8be6-9f70b01d1886",
   "metadata": {},
   "source": [
    "## Examining the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0ddc1-67aa-4688-8643-b5e7d8c973bf",
   "metadata": {},
   "source": [
    "We're done, but let's take some time to look at what we've created. If we open that file up with `roman_datamodels`, we see that the Roman key is tagged with our schema, and the keys are now commented with their titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07db47-0a02-4ee5-9e5f-69077175d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdm = rdm.open('ccsp_example_spear_vela_long-c-iv_v1.0_img.asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24e429-6bfb-4f36-8adf-948aa3821152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testdm.info(max_rows=None, max_cols=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9838ac-d601-42b4-a146-34a62a399514",
   "metadata": {},
   "source": [
    "And we can also retrieve the description and units of these keys programatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a3e31-cd40-4152-a2a7-80f84d19cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testdm.schema_info(\"description\",\"roman.meta.target_coordinates.ra\"))\n",
    "print(testdm.schema_info(\"unit\",\"roman.meta.target_coordinates.ra\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f3ad2-eccd-47e1-a3ce-d95475eb7e65",
   "metadata": {},
   "source": [
    "And because the right branch of `roman_datamodels` is installed into our Python environment, the schema is also similarly registered by the ASDF package while we're in this environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333aff5b-4b6e-4fa8-ade9-5fd7f66d5fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testaf = asdf.open('ccsp_example_spear_vela_long-c-iv_v1.0_img.asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45b114-8c28-4217-85ff-7df11f6193b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "testaf.info(max_rows=None, max_cols=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91589f49-8ce9-4328-b082-20cc581b005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only works because `roman_datamodels` is installed in our environment,\n",
    "# serving to connect the file to its tagged schema\n",
    "print(testaf.schema_info(\"description\",\"roman.meta.target_coordinates.ra\"))\n",
    "print(testaf.schema_info(\"unit\",\"roman.meta.target_coordinates.ra\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7b595-9dd4-4277-8d9d-6fe2812ebb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's finally close the FITS file, now that we're done with it\n",
    "hdul.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
